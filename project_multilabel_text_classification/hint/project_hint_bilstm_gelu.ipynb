{"cells":[{"cell_type":"markdown","source":["## **0. Tải bộ dữ liệu**\n","**Lưu ý:** Nếu không thể tải bằng gdown do bị giới hạn số lượt tải, các bạn hãy tải thủ công và đưa lên drive của mình, sau đó copy từ drive vào colab.\n","```python\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","!cp /path/to/dataset/on/your/drive .\n","```"],"metadata":{"id":"EG4pEApweeMi"}},{"cell_type":"code","source":["# https://drive.google.com/file/d/1f7WAwkuTFgLzCCTs2HZv3AmtBkET4l1M/view?usp=share_link\n","!gdown --id 1f7WAwkuTFgLzCCTs2HZv3AmtBkET4l1M"],"metadata":{"id":"V2H_gNugelj6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip './sem_eval_2018.zip'"],"metadata":{"id":"7RHFkwgge2Nj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **1. Import các thư viện cần thiết**"],"metadata":{"id":"TSsat2oUaitv"}},{"cell_type":"code","source":["!pip install unidecode"],"metadata":{"id":"FD3qFBa8RVS8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x753CoSmVZ1G"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import re\n","import nltk\n","import unidecode\n","\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","\n","RANDOM_SEED = 1\n","tf.random.set_seed(RANDOM_SEED)"]},{"cell_type":"markdown","source":["## **2. Chuẩn bị dữ liệu**"],"metadata":{"id":"YKb5snF9aptz"}},{"cell_type":"code","source":["english_stop_words = stopwords.words('english') # Lấy danh sách stopwords từ thư viện ntlk\n","stemmer = PorterStemmer() # Khai báo stemmer object (dùng để stemming trong hàm normalize text)\n","\n","# Xây dựng hàm text normalization\n","def text_normalize(text):\n","    text = text.lower() # Chuyển chữ viết thường \n","    text = unidecode.unidecode(text) # Mã hóa về ASCII\n","    text = text.strip() # Xóa kí tự đặc biệt ở đầu và cuối string\n","    text = re.sub(r'[^\\w\\s]', '', text) # Loại bỏ dấu câu\n","    text = ' '.join([word for word in text.split(' ') if word not in english_stop_words]) # Xóa stopwords\n","    text = ' '.join([stemmer.stem(word) for word in text.split(' ')]) # Stemming\n"," \n","    return text"],"metadata":{"id":"sfZ3eP0kPsi7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 128\n","MAX_SEQ_LEN = 128\n","MAX_FEATURES = 5000 \n","EMBEDDING_DIMS = 64\n","ROOT_FOLDER_PATH = './sem_eval_2018'\n","\n","train_filepath = os.path.join(ROOT_FOLDER_PATH, 'train.csv')\n","val_filepath = os.path.join(ROOT_FOLDER_PATH, 'val.csv')\n","test_filepath = os.path.join(ROOT_FOLDER_PATH, 'test.csv')\n","\n","train_df = pd.read_csv(train_filepath, \n","                index_col=0) \n","val_df = pd.read_csv(val_filepath, \n","                index_col=0) \n","test_df = pd.read_csv(test_filepath, \n","                index_col=0) \n","\n","train_df['Tweet'] = train_df['Tweet'].apply(lambda p: text_normalize(p)).astype(str) \n","val_df['Tweet'] = val_df['Tweet'].apply(lambda p: text_normalize(p)).astype(str) \n","test_df['Tweet'] = test_df['Tweet'].apply(lambda p: text_normalize(p)).astype(str) \n","\n","class_lst = np.array(train_df.columns[2:])\n","n_classes = len(class_lst)\n","\n","X_train, y_train = train_df['Tweet'].to_numpy(), train_df[class_lst].astype('int').to_numpy()\n","X_val, y_val = val_df['Tweet'].to_numpy(), val_df[class_lst].astype('int').to_numpy()\n","X_test, y_test = test_df['Tweet'].to_numpy(), test_df[class_lst].astype('int').to_numpy()"],"metadata":{"id":"YjSMjEex0gOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(BATCH_SIZE)\n","val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH_SIZE)\n","test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(BATCH_SIZE)"],"metadata":{"id":"5uFnFYkTWfTT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def inverse_label(class_lst, onehot_label):\n","\n","    return class_lst[onehot_label > 0]\n","\n","for text_batch, label_batch in train_ds.take(1):\n","  for i in range(10):\n","    print(\"Text: \", text_batch.numpy()[i])\n","    print(\"Label:\", inverse_label(class_lst, label_batch.numpy()[i]))"],"metadata":{"id":"KT-cAKTNohDl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cấu hình các tham số tối ưu cho việc đọc dữ liệu\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"],"metadata":{"id":"onM2jAEBte9v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **3. Xây dựng mô hình**"],"metadata":{"id":"iBYXRSW8at00"}},{"cell_type":"code","source":["# Khai báo layer text vectorization\n","text_vectorization_layer = tf.keras.layers.TextVectorization(\n","    max_tokens=MAX_FEATURES, # Kích thước bộ từ vựng\n","    output_mode='int', # Giá trị token là chỉ mục của từ trong vocab\n","    output_sequence_length=MAX_SEQ_LEN # Số token tối đa trong 1 vector\n",")\n","\n","train_text = train_ds.map(lambda text, labels: text) # Gọi `content` của toàn bộ mẫu dữ liệu trong tập train\n","text_vectorization_layer.adapt(train_text) # Xây dựng layer vectorization dựa trên dữ liệu tập train"],"metadata":{"id":"d6vAi-z5aw1w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Xây dựng hàm khởi tạo model\n","def build_model(max_features, max_seq_len, embedding_dims, n_classes):\n","    ### BẮT ĐẦU CODE TẠI ĐÂY ###\n","\n","    ### KẾT THÚC CODE TẠI ĐÂY ###\n","\n","    return model"],"metadata":{"id":"2cF-4m92lJXu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = build_model(max_features=MAX_FEATURES, \n","                    max_seq_len=MAX_SEQ_LEN,\n","                    embedding_dims=EMBEDDING_DIMS, \n","                    n_classes=n_classes)\n","model.summary()"],"metadata":{"id":"TsB5ytndbVgt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **4. Cấu hình mô hình**"],"metadata":{"id":"YLf9DMbmbX9M"}},{"cell_type":"code","source":["# Khai báo một số giá trị siêu tham số\n","EPOCHS = 30\n","LR = 1e-4"],"metadata":{"id":"RVY1Eo7wxmbG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cấu hình một số thông tin cho mô hình\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=LR), # Sử dụng optimizer Adam\n","    loss=tf.keras.losses.BinaryCrossentropy(), # Sử dụng hàm loss BinaryCrossEntropy\n","    metrics=['accuracy'] # Sử dụng thêm độ đo đánh giá Accuracy\n",")"],"metadata":{"id":"cR868LBvxoZY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **5. Thực hiện huấn luyện**"],"metadata":{"id":"3Kb90Safbc0I"}},{"cell_type":"code","source":["# Thực hiện huấn luyện\n","history = model.fit( \n","    train_ds, # Huấn luyện với bộ train_ds\n","    validation_data=val_ds, # Đánh giá trên bộ val_ds\n","    epochs=EPOCHS # Huấn luyện với số lần lặp = số epochs\n",")"],"metadata":{"id":"-StpXxgExtFo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **6. Đánh giá và trực quan hóa**"],"metadata":{"id":"UgNNy8JUbfBj"}},{"cell_type":"code","source":["# Đánh giá mô hình trên tập test\n","test_evaluation = model.evaluate(test_ds)"],"metadata":{"id":"b3TlfKI5rc7B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Đọc các kết quả huấn luyện mô hình qua từng epoch\n","train_loss, train_acc = history.history['loss'], history.history['accuracy'] # Đọc thông tin loss, acc trên tập train\n","val_loss, val_acc = history.history['val_loss'], history.history['val_accuracy'] # Đọc thông tin loss, acc trên tập val\n","\n","plt.figure(figsize=(10, 10)) # Cài đặt kích thước khung ảnh\n","\n","plt.subplot(2, 2, 1) # Khởi tạo khung ảnh cho training loss\n","plt.xlabel('Epochs') # Hiển thị tên trục hoành là 'Epochs'\n","plt.ylabel('Loss') # Hiển thị tên trục tung là 'Loss'\n","plt.title('Training loss') # Hiển thị title của khung ảnh hiện tại là 'Training Loss'\n","plt.plot(train_loss, color='green') # Vẽ đường giá trị loss trên tập train qua từng epoch (đường vẽ màu đỏ)\n","\n","plt.subplot(2, 2, 2) # Khởi tạo khung ảnh cho training acc\n","plt.xlabel('Epochs') # Hiển thị tên trục hoành là 'Epochs'\n","plt.ylabel('Accuracy') # Hiển thị tên trục tung là 'Accuracy'\n","plt.title('Training accuracy') # Hiển thị title của khung ảnh hiện tại là 'Training accuracy'\n","plt.plot(train_acc, color='orange') # Vẽ đường giá trị accuracy trên tập train qua từng epoch (đường vẽ màu cam)\n","\n","plt.subplot(2, 2, 3) # Khởi tạo khung ảnh cho val loss\n","plt.xlabel('Epochs') # Hiển thị tên trục hoành là 'Epochs'\n","plt.ylabel('Loss') # Hiển thị tên trục tung là 'Loss'\n","plt.title('Validation loss') # Hiển thị title của khung ảnh hiện tại là 'Validation loss'\n","plt.plot(val_loss, color='green') # Vẽ đường giá trị loss trên tập val qua từng epoch (đường vẽ màu đỏ)\n","\n","plt.subplot(2, 2, 4) # Khởi tạo khung ảnh cho val acc\n","plt.xlabel('Epochs') # Hiển thị tên trục hoành là 'Epochs'\n","plt.ylabel('Accuracy') # Hiển thị tên trục tung là 'Accuracy'\n","plt.title('Validation accuracy') # Hiển thị title của khung ảnh hiện tại là 'Validation accuracy'\n","plt.plot(val_acc, color='orange') # Vẽ đường giá trị accuracy trên tập val qua từng epoch (đường vẽ màu cam)\n","\n","plt.show() # Hiển thị 4 khung ảnh nhỏ"],"metadata":{"id":"vmMe97kpcS71"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **7. Inference**"],"metadata":{"id":"8pSQL9BO0sry"}},{"cell_type":"code","source":["threshold = 0.4\n","\n","for text_batch, label_batch in test_ds.take(1):\n","    for i in range(10):\n","        input_text = text_batch[i].numpy()\n","        label = label_batch[i].numpy()\n","        pred = model.predict(np.expand_dims(input_text, 0), verbose=0)[0]\n","        threshold_pred = np.where(pred > threshold, 1, 0)\n","        print(f\"Text: {input_text}\")\n","        print(f\"Label: {inverse_label(class_lst, label)}\")\n","        print(f\"Predicted Label(s): ({inverse_label(class_lst, threshold_pred)})\")\n","        print(\" \")"],"metadata":{"id":"djBwR4Pd0vTu"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"gpuClass":"premium"},"nbformat":4,"nbformat_minor":0}